{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64d3252a-b89f-41ea-a65d-61f6c5ebd823",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (144934965.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    configs/segnext/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512.py \\\u001b[0m\n\u001b[0m                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "PYTHONPATH=. python tools/test.py \\\n",
    "  configs/segnext/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512.py \\\n",
    "  work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512/iter_20000.pth \\\n",
    "  --work-dir work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512 \\\n",
    "  --show-dir work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512/test_vis \\\n",
    "  --cfg-options val_evaluator.type=IoUMetric val_evaluator.iou_metrics='[\"mIoU\"]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bcaecda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONPATH=.\n",
      "/bin/sh: 1: gcc: not found\n",
      "05/14 08:45:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.13 (main, Sep 11 2023, 13:44:35) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 750847637\n",
      "    GPU 0: Quadro RTX 6000\n",
      "    CUDA_HOME: None\n",
      "    GCC: n/a\n",
      "    PyTorch: 2.1.0\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "    TorchVision: 0.16.0\n",
      "    OpenCV: 4.11.0\n",
      "    MMEngine: 0.10.7\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: True\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 750847637\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n",
      "05/14 08:45:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "checkpoint_file = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segnext/mscan_l_20230227-cef260d4.pth'\n",
      "crop_size = (\n",
      "    512,\n",
      "    512,\n",
      ")\n",
      "data_preprocessor = dict(\n",
      "    bgr_to_rgb=True,\n",
      "    mean=[\n",
      "        123.675,\n",
      "        116.28,\n",
      "        103.53,\n",
      "    ],\n",
      "    pad_val=0,\n",
      "    seg_pad_val=255,\n",
      "    size=(\n",
      "        512,\n",
      "        512,\n",
      "    ),\n",
      "    std=[\n",
      "        58.395,\n",
      "        57.12,\n",
      "        57.375,\n",
      "    ],\n",
      "    test_cfg=dict(size_divisor=32),\n",
      "    type='SegDataPreProcessor')\n",
      "data_root = 'data/plantseg115'\n",
      "dataset_type = 'PlantSeg115Dataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(by_epoch=False, interval=5000, type='CheckpointHook'),\n",
      "    logger=dict(interval=500, log_metric_by_epoch=False, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    timer=dict(type='IterTimerHook'),\n",
      "    visualization=dict(type='SegVisualizationHook'))\n",
      "default_scope = 'mmseg'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=True,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "ham_norm_cfg = dict(num_groups=32, requires_grad=True, type='GN')\n",
      "img_ratios = [\n",
      "    0.5,\n",
      "    0.75,\n",
      "    1.0,\n",
      "    1.25,\n",
      "    1.5,\n",
      "    1.75,\n",
      "]\n",
      "launcher = 'none'\n",
      "load_from = 'work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512/iter_8000.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=False)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        act_cfg=dict(type='GELU'),\n",
      "        attention_kernel_paddings=[\n",
      "            2,\n",
      "            [\n",
      "                0,\n",
      "                3,\n",
      "            ],\n",
      "            [\n",
      "                0,\n",
      "                5,\n",
      "            ],\n",
      "            [\n",
      "                0,\n",
      "                10,\n",
      "            ],\n",
      "        ],\n",
      "        attention_kernel_sizes=[\n",
      "            5,\n",
      "            [\n",
      "                1,\n",
      "                7,\n",
      "            ],\n",
      "            [\n",
      "                1,\n",
      "                11,\n",
      "            ],\n",
      "            [\n",
      "                1,\n",
      "                21,\n",
      "            ],\n",
      "        ],\n",
      "        depths=[\n",
      "            3,\n",
      "            5,\n",
      "            27,\n",
      "            3,\n",
      "        ],\n",
      "        drop_path_rate=0.3,\n",
      "        drop_rate=0.0,\n",
      "        embed_dims=[\n",
      "            64,\n",
      "            128,\n",
      "            320,\n",
      "            512,\n",
      "        ],\n",
      "        init_cfg=dict(\n",
      "            checkpoint=\n",
      "            'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/segnext/mscan_l_20230227-cef260d4.pth',\n",
      "            type='Pretrained'),\n",
      "        mlp_ratios=[\n",
      "            8,\n",
      "            8,\n",
      "            4,\n",
      "            4,\n",
      "        ],\n",
      "        norm_cfg=dict(requires_grad=True, type='BN'),\n",
      "        type='MSCAN'),\n",
      "    data_preprocessor=dict(\n",
      "        bgr_to_rgb=True,\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        pad_val=0,\n",
      "        seg_pad_val=255,\n",
      "        size=(\n",
      "            512,\n",
      "            512,\n",
      "        ),\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        test_cfg=dict(size_divisor=32),\n",
      "        type='SegDataPreProcessor'),\n",
      "    decode_head=dict(\n",
      "        align_corners=False,\n",
      "        channels=1024,\n",
      "        dropout_ratio=0.1,\n",
      "        ham_channels=1024,\n",
      "        ham_kwargs=dict(\n",
      "            MD_R=16,\n",
      "            MD_S=1,\n",
      "            eval_steps=7,\n",
      "            inv_t=100,\n",
      "            rand_init=True,\n",
      "            train_steps=6),\n",
      "        in_channels=[\n",
      "            128,\n",
      "            320,\n",
      "            512,\n",
      "        ],\n",
      "        in_index=[\n",
      "            1,\n",
      "            2,\n",
      "            3,\n",
      "        ],\n",
      "        loss_decode=dict(\n",
      "            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),\n",
      "        norm_cfg=dict(num_groups=32, requires_grad=True, type='GN'),\n",
      "        num_classes=116,\n",
      "        type='LightHamHead'),\n",
      "    pretrained=None,\n",
      "    test_cfg=dict(mode='whole'),\n",
      "    train_cfg=dict(),\n",
      "    type='EncoderDecoder')\n",
      "optim_wrapper = dict(\n",
      "    optimizer=dict(\n",
      "        betas=(\n",
      "            0.9,\n",
      "            0.999,\n",
      "        ), lr=6e-05, type='AdamW', weight_decay=0.01),\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            head=dict(lr_mult=10.0),\n",
      "            norm=dict(decay_mult=0.0),\n",
      "            pos_block=dict(decay_mult=0.0))),\n",
      "    type='OptimWrapper')\n",
      "optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0, by_epoch=False, end=1500, start_factor=1e-06,\n",
      "        type='LinearLR'),\n",
      "    dict(\n",
      "        begin=1500,\n",
      "        by_epoch=False,\n",
      "        end=160000,\n",
      "        eta_min=0.0,\n",
      "        power=1.0,\n",
      "        type='PolyLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/test', seg_map_path='annotations/test'),\n",
      "        data_root='data/plantseg115',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        reduce_zero_label=False,\n",
      "        type='PlantSeg115Dataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "    ], type='IoUMetric')\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(keep_ratio=True, scale=(\n",
      "        2048,\n",
      "        512,\n",
      "    ), type='Resize'),\n",
      "    dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_iters=40000, type='IterBasedTrainLoop', val_interval=10000)\n",
      "train_dataloader = dict(\n",
      "    batch_size=8,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/train', seg_map_path='annotations/train'),\n",
      "        data_root='data/plantseg115',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(\n",
      "                keep_ratio=True,\n",
      "                ratio_range=(\n",
      "                    0.5,\n",
      "                    2.0,\n",
      "                ),\n",
      "                scale=(\n",
      "                    2048,\n",
      "                    512,\n",
      "                ),\n",
      "                type='RandomResize'),\n",
      "            dict(\n",
      "                cat_max_ratio=0.75, crop_size=(\n",
      "                    512,\n",
      "                    512,\n",
      "                ), type='RandomCrop'),\n",
      "            dict(prob=0.5, type='RandomFlip'),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        reduce_zero_label=False,\n",
      "        type='PlantSeg115Dataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='InfiniteSampler'))\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "    dict(\n",
      "        keep_ratio=True,\n",
      "        ratio_range=(\n",
      "            0.5,\n",
      "            2.0,\n",
      "        ),\n",
      "        scale=(\n",
      "            2048,\n",
      "            512,\n",
      "        ),\n",
      "        type='RandomResize'),\n",
      "    dict(cat_max_ratio=0.75, crop_size=(\n",
      "        512,\n",
      "        512,\n",
      "    ), type='RandomCrop'),\n",
      "    dict(prob=0.5, type='RandomFlip'),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(type='PackSegInputs'),\n",
      "]\n",
      "tta_model = dict(type='SegTTAModel')\n",
      "tta_pipeline = [\n",
      "    dict(backend_args=None, type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        transforms=[\n",
      "            [\n",
      "                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),\n",
      "                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),\n",
      "            ],\n",
      "            [\n",
      "                dict(direction='horizontal', prob=0.0, type='RandomFlip'),\n",
      "                dict(direction='horizontal', prob=1.0, type='RandomFlip'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='LoadAnnotations'),\n",
      "            ],\n",
      "            [\n",
      "                dict(type='PackSegInputs'),\n",
      "            ],\n",
      "        ],\n",
      "        type='TestTimeAug'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        data_prefix=dict(\n",
      "            img_path='images/test', seg_map_path='annotations/test'),\n",
      "        data_root='data/plantseg115',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(keep_ratio=True, scale=(\n",
      "                2048,\n",
      "                512,\n",
      "            ), type='Resize'),\n",
      "            dict(reduce_zero_label=False, type='LoadAnnotations'),\n",
      "            dict(type='PackSegInputs'),\n",
      "        ],\n",
      "        reduce_zero_label=False,\n",
      "        type='PlantSeg115Dataset'),\n",
      "    num_workers=4,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(\n",
      "    iou_metrics=[\n",
      "        'mIoU',\n",
      "    ], type='IoUMetric')\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    name='visualizer',\n",
      "    type='SegLocalVisualizer',\n",
      "    vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = 'work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512'\n",
      "\n",
      "/workspace/PlantSeg/mmseg/models/losses/cross_entropy_loss.py:250: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
      "  warnings.warn(\n",
      "05/14 08:45:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "/workspace/PlantSeg/mmseg/engine/hooks/visualization_hook.py:60: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.\n",
      "  warnings.warn('The draw is False, it means that the '\n",
      "05/14 08:45:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SegVisualizationHook               \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "/workspace/PlantSeg/mmseg/datasets/transforms/loading.py:84: UserWarning: `reduce_zero_label` will be deprecated, if you would like to ignore the zero label, please set `reduce_zero_label=True` when dataset initialized\n",
      "  warnings.warn('`reduce_zero_label` will be deprecated, '\n",
      "05/14 08:45:13 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The prefix is not set in metric class IoUMetric.\n",
      "Loads checkpoint by local backend from path: work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512/iter_8000.pth\n",
      "05/14 08:45:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512/iter_8000.pth\n",
      "05/14 08:47:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [ 500/2295]    eta: 0:07:14  time: 0.3383  data_time: 0.0026  memory: 17085  \n",
      "05/14 08:47:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [1000/2295]    eta: 0:03:21  time: 0.0577  data_time: 0.0026  memory: 13295  \n",
      "05/14 08:48:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [1500/2295]    eta: 0:01:40  time: 0.1448  data_time: 0.0025  memory: 13285  \n",
      "05/14 08:48:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [2000/2295]    eta: 0:00:33  time: 0.0646  data_time: 0.0030  memory: 13300  \n",
      "05/14 08:49:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - per class results:\n",
      "05/14 08:49:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "+-------------------------------------------+-------+-------+\n",
      "|                   Class                   |  IoU  |  Acc  |\n",
      "+-------------------------------------------+-------+-------+\n",
      "|                                           | 90.13 | 95.76 |\n",
      "|              apple black rot              | 24.18 | 29.33 |\n",
      "|             apple mosaic virus            | 46.46 | 52.35 |\n",
      "|                 apple rust                | 41.78 | 43.19 |\n",
      "|                 apple scab                | 35.51 |  45.9 |\n",
      "|             banana anthracnose            |  46.9 | 91.27 |\n",
      "|          banana black leaf streak         | 75.67 | 95.42 |\n",
      "|             banana bunchy top             | 29.74 | 53.79 |\n",
      "|            banana cigar end rot           | 27.24 | 47.53 |\n",
      "|          banana cordana leaf spot         |  57.3 | 71.47 |\n",
      "|           banana panama disease           | 77.66 | 81.98 |\n",
      "|             basil downy mildew            | 40.58 | 50.13 |\n",
      "|              bean halo blight             |  0.13 |  0.13 |\n",
      "|             bean mosaic virus             |  0.0  |  0.0  |\n",
      "|                 bean rust                 | 28.13 | 36.93 |\n",
      "|         bell pepper bacterial spot        |  2.34 |  2.36 |\n",
      "|        bell pepper blossom end rot        | 57.03 | 59.36 |\n",
      "|       bell pepper frogeye leaf spot       |  0.77 |  0.82 |\n",
      "|         bell pepper powdery mildew        | 39.31 | 43.31 |\n",
      "|           blueberry anthracnose           | 21.76 | 72.99 |\n",
      "|         blueberry botrytis blight         |  3.75 |  4.0  |\n",
      "|           blueberry mummy berry           | 22.67 | 24.68 |\n",
      "|               blueberry rust              |  0.7  |  0.7  |\n",
      "|              blueberry scorch             | 12.13 | 12.39 |\n",
      "|       broccoli alternaria leaf spot       |  0.0  |  0.0  |\n",
      "|           broccoli downy mildew           |  0.0  |  0.0  |\n",
      "|             broccoli ring spot            |  0.0  |  0.0  |\n",
      "|        cabbage alternaria leaf spot       | 10.92 | 29.11 |\n",
      "|             cabbage black rot             | 39.38 | 43.88 |\n",
      "|            cabbage downy mildew           | 32.42 | 34.69 |\n",
      "|       carrot alternaria leaf blight       | 29.32 | 92.54 |\n",
      "|             carrot cavity spot            |  37.6 | 43.44 |\n",
      "|       carrot cercospora leaf blight       | 32.57 |  36.0 |\n",
      "|      cauliflower alternaria leaf spot     |  0.0  |  0.0  |\n",
      "|       cauliflower bacterial soft rot      | 25.31 | 28.93 |\n",
      "|             celery anthracnose            |  0.0  |  0.0  |\n",
      "|            celery early blight            | 24.67 | 32.41 |\n",
      "|              cherry leaf spot             | 16.12 | 19.31 |\n",
      "|           cherry powdery mildew           | 13.53 | 15.51 |\n",
      "|               citrus canker               | 48.68 | 57.41 |\n",
      "|          citrus greening disease          | 35.28 | 58.41 |\n",
      "|            coffee berry blotch            | 14.69 | 41.17 |\n",
      "|              coffee black rot             |  0.0  |  0.0  |\n",
      "|           coffee brown eye spot           |  0.0  |  0.0  |\n",
      "|              coffee leaf rust             | 54.97 | 57.22 |\n",
      "|            corn gray leaf spot            | 17.55 | 17.96 |\n",
      "|         corn northern leaf blight         | 19.86 | 31.09 |\n",
      "|                 corn rust                 | 66.13 | 93.91 |\n",
      "|                 corn smut                 | 76.49 | 97.11 |\n",
      "|         cucumber angular leaf spot        | 23.65 | 26.27 |\n",
      "|          cucumber bacterial wilt          |  0.12 |  0.12 |\n",
      "|          cucumber powdery mildew          |  1.37 |  1.4  |\n",
      "|       eggplant cercospora leaf spot       |  0.0  |  0.0  |\n",
      "|        eggplant phomopsis fruit rot       | 11.32 | 54.97 |\n",
      "|        eggplant phytophthora blight       |  4.37 |  4.46 |\n",
      "|             garlic leaf blight            |  6.17 | 24.69 |\n",
      "|                garlic rust                | 14.43 | 18.98 |\n",
      "|              ginger leaf spot             |  0.0  |  0.0  |\n",
      "|            ginger sheath blight           |  0.0  |  0.0  |\n",
      "|              grape black rot              |  32.4 | 41.97 |\n",
      "|             grape downy mildew            | 50.62 | 62.13 |\n",
      "|              grape leaf spot              | 15.55 | 15.68 |\n",
      "|         grapevine leafroll disease        | 71.11 | 82.85 |\n",
      "|            lettuce downy mildew           | 38.88 | 51.67 |\n",
      "|            lettuce mosaic virus           |  0.0  |  0.0  |\n",
      "|               maple tar spot              | 40.01 | 50.78 |\n",
      "|             peach anthracnose             |  0.0  |  0.0  |\n",
      "|              peach brown rot              | 80.39 |  84.0 |\n",
      "|              peach leaf curl              |  63.8 | 79.77 |\n",
      "|                 peach rust                |  0.0  |  0.0  |\n",
      "|                 peach scab                | 70.87 | 82.13 |\n",
      "|            plum bacterial spot            |  0.0  |  0.0  |\n",
      "|               plum brown rot              | 22.64 | 24.17 |\n",
      "|            plum pocket disease            |  17.6 | 28.42 |\n",
      "|               plum pox virus              | 15.29 | 15.94 |\n",
      "|                 plum rust                 | 13.34 | 17.09 |\n",
      "|            potato early blight            |  3.12 |  3.63 |\n",
      "|             potato late blight            | 33.23 | 53.69 |\n",
      "|           raspberry fire blight           |  12.9 | 21.52 |\n",
      "|            raspberry gray mold            | 43.64 |  83.2 |\n",
      "|            raspberry leaf spot            |  0.6  |  0.6  |\n",
      "|           raspberry yellow rust           | 60.08 | 68.24 |\n",
      "|                 rice blast                | 43.54 | 51.32 |\n",
      "|             rice sheath blight            |  5.15 |  5.49 |\n",
      "|          soybean bacterial blight         | 16.31 | 21.72 |\n",
      "|             soybean brown spot            | 43.16 | 92.55 |\n",
      "|            soybean downy mildew           | 67.61 | 80.74 |\n",
      "|         soybean frog eye leaf spot        | 59.32 |  89.6 |\n",
      "|               soybean mosaic              |  55.9 | 71.98 |\n",
      "|                soybean rust               | 40.03 | 79.43 |\n",
      "|           squash powdery mildew           | 23.88 | 65.91 |\n",
      "|           strawberry anthracnose          | 59.45 | 63.47 |\n",
      "|           strawberry leaf scorch          | 52.48 | 77.14 |\n",
      "|             tobacco blue mold             |  6.37 |  8.79 |\n",
      "|             tobacco brown spot            | 29.04 | 41.57 |\n",
      "|         tobacco frogeye leaf spot         |  0.0  |  0.0  |\n",
      "|            tobacco mosaic virus           | 31.74 | 34.43 |\n",
      "|         tomato bacterial leaf spot        |  0.44 |  0.45 |\n",
      "|            tomato early blight            | 21.21 | 44.85 |\n",
      "|             tomato late blight            | 25.72 | 41.63 |\n",
      "|              tomato leaf mold             | 37.01 | 45.15 |\n",
      "|            tomato mosaic virus            | 15.36 |  17.5 |\n",
      "|         tomato septoria leaf spot         | 30.88 |  40.7 |\n",
      "|       tomato yellow leaf curl virus       | 37.95 | 52.36 |\n",
      "| wheat bacterial leaf streak (black chaff) |  2.76 |  2.81 |\n",
      "|              wheat head scab              | 50.55 | 55.32 |\n",
      "|              wheat leaf rust              | 36.66 | 46.76 |\n",
      "|              wheat loose smut             | 70.09 | 92.63 |\n",
      "|            wheat powdery mildew           | 60.88 | 88.05 |\n",
      "|           wheat septoria blotch           | 57.49 | 75.09 |\n",
      "|              wheat stem rust              | 54.39 | 75.93 |\n",
      "|             wheat stripe rust             | 58.98 | 67.08 |\n",
      "|          zucchini bacterial wilt          | 18.36 |  48.4 |\n",
      "|           zucchini downy mildew           |  0.0  |  0.0  |\n",
      "|          zucchini powdery mildew          | 14.77 |  19.3 |\n",
      "|        zucchini yellow mosaic virus       | 42.69 | 60.26 |\n",
      "+-------------------------------------------+-------+-------+\n",
      "05/14 08:49:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Iter(test) [2295/2295]    aAcc: 87.5600  mIoU: 28.4100  mAcc: 38.8200  data_time: 0.0033  time: 0.1070\n"
     ]
    }
   ],
   "source": [
    "# Set PYTHONPATH if needed\n",
    "%env PYTHONPATH=.\n",
    "\n",
    "# Run model evaluation and compute mIoU on the validation set\n",
    "!python tools/test.py \\\n",
    "  configs/segnext/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512.py \\\n",
    "  work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512/iter_8000.pth \\\n",
    "  --cfg-options val_evaluator.type=IoUMetric val_evaluator.iou_metrics=\"['mIoU']\" \\\n",
    "  --work-dir work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01e1cb73-4916-480c-9c95-4386e14c52b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint size: 562.50 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = 'work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512/iter_8000.pth'\n",
    "size_mb = os.path.getsize(path) / (1024 * 1024)\n",
    "print(f\"Checkpoint size: {size_mb:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f9ae9f2-3e2c-4681-9436-2d738d1222df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512/iter_8000.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: gcc: not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä === SegNeXt Serving Performance Report ===\n",
      "üíæ Model Size on Disk: 562.50 MB\n",
      "‚è±Ô∏è Inference Latency (median): 41.89 ms\n",
      "‚è±Ô∏è Inference Latency (95th percentile): 42.33 ms\n",
      "‚è±Ô∏è Inference Latency (99th percentile): 50.06 ms\n",
      "üöÄ Inference Throughput (single sample): 23.68 FPS\n",
      "üöÄ Batch Throughput: 23.83 FPS\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import logging\n",
    "from mmseg.apis import init_model\n",
    "from mmengine.config import Config\n",
    "from mmseg.registry import RUNNERS\n",
    "\n",
    "# ‚úÇÔ∏è Suppress excessive logging\n",
    "logging.getLogger('mmengine').setLevel(logging.ERROR)\n",
    "\n",
    "# ‚úÖ Path configuration\n",
    "config_path = 'configs/segnext/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512.py'\n",
    "checkpoint_path = 'work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512/iter_8000.pth'\n",
    "\n",
    "# ‚úÖ Load config and model\n",
    "cfg = Config.fromfile(config_path)\n",
    "cfg.log_level = 'ERROR'\n",
    "cfg.work_dir = 'work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512'\n",
    "model = init_model(cfg, checkpoint_path, device='cuda')\n",
    "model.eval()\n",
    "\n",
    "# ‚úÖ Build runner and obtain the test_loader (includes inputs and data_samples)\n",
    "runner = RUNNERS.build(cfg)\n",
    "test_loader = runner.test_dataloader\n",
    "\n",
    "# ‚úÖ Fetch one batch and move it to CUDA\n",
    "batch_data = next(iter(test_loader))\n",
    "batch_data = {\n",
    "    k: [x.to('cuda') for x in v] if isinstance(v, list) else v\n",
    "    for k, v in batch_data.items()\n",
    "}\n",
    "\n",
    "# ‚úÖ Warm-up pass\n",
    "with torch.no_grad():\n",
    "    _ = model.test_step(batch_data)\n",
    "\n",
    "# ‚úÖ Latency test: multiple forward passes on a single batch\n",
    "num_trials = 100\n",
    "latencies = []\n",
    "with torch.no_grad():\n",
    "    for _ in range(num_trials):\n",
    "        start = time.time()\n",
    "        _ = model.test_step(batch_data)\n",
    "        latencies.append(time.time() - start)\n",
    "\n",
    "# ‚úÖ Throughput test: measure processing speed over multiple batches\n",
    "num_batches = 50\n",
    "batch_times = []\n",
    "with torch.no_grad():\n",
    "    for _ in range(num_batches):\n",
    "        start = time.time()\n",
    "        _ = model.test_step(batch_data)\n",
    "        batch_times.append(time.time() - start)\n",
    "\n",
    "# ‚úÖ Calculate model file size\n",
    "model_size = os.path.getsize(checkpoint_path)\n",
    "\n",
    "# ‚úÖ Print performance report\n",
    "print(\"\\nüìä === SegNeXt Serving Performance Report ===\")\n",
    "print(f\"üíæ Model Size on Disk: {model_size / (1024 ** 2):.2f} MB\")\n",
    "print(f\"‚è±Ô∏è Inference Latency (median): {np.percentile(latencies, 50) * 1000:.2f} ms\")\n",
    "print(f\"‚è±Ô∏è Inference Latency (95th percentile): {np.percentile(latencies, 95) * 1000:.2f} ms\")\n",
    "print(f\"‚è±Ô∏è Inference Latency (99th percentile): {np.percentile(latencies, 99) * 1000:.2f} ms\")\n",
    "print(f\"üöÄ Inference Throughput (single sample): {num_trials / np.sum(latencies):.2f} FPS\")\n",
    "print(f\"üöÄ Batch Throughput: {len(batch_data['inputs']) * num_batches / np.sum(batch_times):.2f} FPS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8e2dc07-94fc-4258-b741-2e535342070c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512/iter_8000.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: gcc: not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä === SegNeXt Serving Performance Report ===\n",
      "üíæ Model Size on Disk: 562.50 MB\n",
      "‚è±Ô∏è Inference Latency (median): 775.14 ms\n",
      "‚è±Ô∏è Inference Latency (95th percentile): 786.92 ms\n",
      "‚è±Ô∏è Inference Latency (99th percentile): 794.41 ms\n",
      "üöÄ Inference Throughput (single sample): 1.30 FPS\n",
      "üöÄ Batch Throughput: 1.31 FPS\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import logging\n",
    "from mmseg.apis import init_model\n",
    "from mmengine.config import Config\n",
    "from mmseg.registry import RUNNERS\n",
    "\n",
    "# ‚úÇÔ∏è Suppress excessive logging\n",
    "logging.getLogger('mmengine').setLevel(logging.ERROR)\n",
    "\n",
    "# ‚úÖ Path configuration\n",
    "config_path = 'configs/segnext/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512.py'\n",
    "checkpoint_path = 'work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512/iter_8000.pth'\n",
    "\n",
    "# ‚úÖ Load config and model\n",
    "cfg = Config.fromfile(config_path)\n",
    "cfg.log_level = 'ERROR'\n",
    "cfg.work_dir = 'work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512'\n",
    "model = init_model(cfg, checkpoint_path, device='cpu')\n",
    "model.eval()\n",
    "\n",
    "# ‚úÖ Build runner and obtain the test_loader (includes inputs and data_samples)\n",
    "runner = RUNNERS.build(cfg)\n",
    "test_loader = runner.test_dataloader\n",
    "\n",
    "# ‚úÖ Fetch one batch and move it to CPU\n",
    "batch_data = next(iter(test_loader))\n",
    "batch_data = {\n",
    "    k: [x.to('cpu') for x in v] if isinstance(v, list) else v\n",
    "    for k, v in batch_data.items()\n",
    "}\n",
    "\n",
    "# ‚úÖ Warm-up pass\n",
    "with torch.no_grad():\n",
    "    _ = model.test_step(batch_data)\n",
    "\n",
    "# ‚úÖ Latency test: multiple forward passes on a single batch\n",
    "num_trials = 100\n",
    "latencies = []\n",
    "with torch.no_grad():\n",
    "    for _ in range(num_trials):\n",
    "        start = time.time()\n",
    "        _ = model.test_step(batch_data)\n",
    "        latencies.append(time.time() - start)\n",
    "\n",
    "# ‚úÖ Throughput test: measure processing speed over multiple batches\n",
    "num_batches = 50\n",
    "batch_times = []\n",
    "with torch.no_grad():\n",
    "    for _ in range(num_batches):\n",
    "        start = time.time()\n",
    "        _ = model.test_step(batch_data)\n",
    "        batch_times.append(time.time() - start)\n",
    "\n",
    "# ‚úÖ Calculate model file size\n",
    "model_size = os.path.getsize(checkpoint_path)\n",
    "\n",
    "# ‚úÖ Print performance report\n",
    "print(\"\\nüìä === SegNeXt Serving Performance Report ===\")\n",
    "print(f\"üíæ Model Size on Disk: {model_size / (1024 ** 2):.2f} MB\")\n",
    "print(f\"‚è±Ô∏è Inference Latency (median): {np.percentile(latencies, 50) * 1000:.2f} ms\")\n",
    "print(f\"‚è±Ô∏è Inference Latency (95th percentile): {np.percentile(latencies, 95) * 1000:.2f} ms\")\n",
    "print(f\"‚è±Ô∏è Inference Latency (99th percentile): {np.percentile(latencies, 99) * 1000:.2f} ms\")\n",
    "print(f\"üöÄ Inference Throughput (single sample): {num_trials / np.sum(latencies):.2f} FPS\")\n",
    "print(f\"üöÄ Batch Throughput: {len(batch_data['inputs']) * num_batches / np.sum(batch_times):.2f} FPS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ac1ef39-9597-403f-8545-692970fdc0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512/iter_8000.pth\n",
      "‚úÖ Loaded trained model from: work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512/iter_8000.pth\n",
      "‚úÖ ONNX model successfully saved to: work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512/segnext_plantseg_iter8000.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from mmseg.apis import init_model\n",
    "from mmengine.config import Config\n",
    "import os\n",
    "\n",
    "# Paths to config and checkpoint\n",
    "config_path = 'configs/segnext/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512.py'\n",
    "checkpoint_path = 'work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512/iter_8000.pth'\n",
    "\n",
    "# Define ONNX output path in the same directory as the checkpoint\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "onnx_output_path = os.path.join(checkpoint_dir, 'segnext_plantseg_iter8000.onnx')\n",
    "\n",
    "# Load model config and weights\n",
    "cfg = Config.fromfile(config_path)\n",
    "cfg.model.pretrained = None\n",
    "model = init_model(cfg, checkpoint_path, device='cuda')\n",
    "model.eval()\n",
    "\n",
    "print(f\"Loaded trained model from: {checkpoint_path}\")\n",
    "\n",
    "# Create dummy input of shape 512x512\n",
    "dummy_input = torch.randn(1, 3, 512, 512, device='cuda')\n",
    "\n",
    "# Export to ONNX\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    onnx_output_path,\n",
    "    export_params=True,\n",
    "    opset_version=11,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size'},\n",
    "        'output': {0: 'batch_size'}\n",
    "    }\n",
    ")\n",
    "\n",
    "# Confirm export\n",
    "if os.path.exists(onnx_output_path):\n",
    "    print(f\"ONNX model successfully saved to: {onnx_output_path}\")\n",
    "else:\n",
    "    print(\"Failed to save ONNX model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d598d37-3386-416e-9576-f3a28f6ce58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch CUDA available: True\n",
      "Torch CUDA version: 11.8\n",
      "cuDNN version: 8700\n",
      "Device name: Quadro RTX 6000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Torch CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Torch CUDA version:\", torch.version.cuda)\n",
    "print(\"cuDNN version:\", torch.backends.cudnn.version())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "import onnxruntime as ort\n",
    "print(\"ONNXRuntime version:\", ort.__version__)\n",
    "print(\"Available providers:\", ort.get_available_providers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed595944-370b-46a3-8e42-801c1e71db92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 02:08:32.673561248 [W:onnxruntime:, session_state.cc:1030 VerifyEachNodeIsAssignedToAnEp] Some nodes were not assigned to the preferred execution providers which may or may not have an negative impact on performance. e.g. ORT explicitly assigns shape related ops to CPU to improve perf.\n",
      "2025-05-13 02:08:32.673582553 [W:onnxruntime:, session_state.cc:1032 VerifyEachNodeIsAssignedToAnEp] Rerunning with verbose output on a non-minimal build will show node assignments.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2295/2295 [05:57<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä === ONNX Model Evaluation Report ===\n",
      "üíæ Model Size on Disk: 187.20 MB\n",
      "üéØ Pixel Accuracy: 85.60%\n",
      "üìè mIoU: 27.28%\n",
      "‚è±Ô∏è  Inference Latency (median): 39.22 ms\n",
      "‚è±Ô∏è  Inference Latency (95%): 45.77 ms\n",
      "üöÄ  Throughput (single): 25.03 FPS\n",
      "üöÄ  Batch Throughput (BS=4): 7.07 FPS\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import cv2\n",
    "from glob import glob\n",
    "\n",
    "# Path to the ONNX model\n",
    "onnx_path = 'work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512/segnext_plantseg_iter8000.onnx'\n",
    "onnx_model_size = os.path.getsize(onnx_path) / (1024 * 1024)\n",
    "\n",
    "# Create ONNXRuntime session (use GPU if available)\n",
    "session = ort.InferenceSession(onnx_path, providers=['CUDAExecutionProvider'])\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "# Image preprocessing (follows MMSeg mean/std normalization)\n",
    "def preprocess(img):  # img: np.ndarray, shape (H, W, 3), BGR format\n",
    "    img = cv2.resize(img, (512, 512))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32)\n",
    "    mean = np.array([123.675, 116.28, 103.53])\n",
    "    std = np.array([58.395, 57.12, 57.375])\n",
    "    img = (img - mean) / std\n",
    "    img = np.transpose(img, (2, 0, 1))  # HWC -> CHW\n",
    "    img = np.expand_dims(img, axis=0)  # CHW -> NCHW\n",
    "    return img.astype(np.float32)\n",
    "\n",
    "# Load dataset\n",
    "img_dir = 'data/plantseg115/images/test'\n",
    "gt_dir  = 'data/plantseg115/annotations/test'\n",
    "img_paths = sorted(glob(f\"{img_dir}/*.jpg\"))\n",
    "gt_paths  = sorted(glob(f\"{gt_dir}/*.png\"))\n",
    "\n",
    "assert len(img_paths) == len(gt_paths) and len(img_paths) > 0, \"No image-label pairs found!\"\n",
    "\n",
    "# Run accuracy and mIoU evaluation\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for img_path, gt_path in tqdm(zip(img_paths, gt_paths), total=len(img_paths)):\n",
    "    img = preprocess(cv2.imread(img_path))  # shape (1, 3, 512, 512)\n",
    "    gt  = cv2.imread(gt_path, cv2.IMREAD_GRAYSCALE)\n",
    "    gt  = cv2.resize(gt, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    pred_logits = session.run([output_name], {input_name: img})[0]  # shape: (1, 116, 64, 64)\n",
    "    pred_mask = np.argmax(pred_logits[0], axis=0)                   # shape: (64, 64)\n",
    "\n",
    "    # Upsample prediction to 512x512\n",
    "    pred_mask = cv2.resize(pred_mask.astype(np.uint8), (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    valid = gt != 255\n",
    "    all_preds.extend(pred_mask[valid].flatten())\n",
    "    all_labels.extend(gt[valid].flatten())\n",
    "\n",
    "# Compute accuracy and mIoU\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "conf = confusion_matrix(all_labels, all_preds, labels=range(116))\n",
    "intersection = np.diag(conf)\n",
    "union = conf.sum(1) + conf.sum(0) - intersection\n",
    "miou = (intersection / np.maximum(union, 1)).mean()\n",
    "\n",
    "# Measure latency for single-image inference\n",
    "latencies = []\n",
    "dummy_img = preprocess(cv2.imread(img_paths[0]))\n",
    "\n",
    "for _ in range(100):\n",
    "    start = time.time()\n",
    "    _ = session.run(None, {input_name: dummy_img})\n",
    "    latencies.append(time.time() - start)\n",
    "\n",
    "# Measure throughput for batched inference\n",
    "batch_input = np.repeat(dummy_img, repeats=4, axis=0)  # batch size = 4\n",
    "batch_times = []\n",
    "for _ in range(50):\n",
    "    start = time.time()\n",
    "    _ = session.run(None, {input_name: batch_input})\n",
    "    batch_times.append(time.time() - start)\n",
    "\n",
    "# Print evaluation summary\n",
    "print(\"\\n=== ONNX Model Evaluation Report ===\")\n",
    "print(f\"Model Size on Disk: {onnx_model_size:.2f} MB\")\n",
    "print(f\"Pixel Accuracy: {acc * 100:.2f}%\")\n",
    "print(f\"mIoU: {miou * 100:.2f}%\")\n",
    "print(f\"Inference Latency (median): {np.median(latencies)*1000:.2f} ms\")\n",
    "print(f\"Inference Latency (95th percentile): {np.percentile(latencies, 95)*1000:.2f} ms\")\n",
    "print(f\"Throughput (single): {1 / np.mean(latencies):.2f} FPS\")\n",
    "print(f\"Batch Throughput (batch size = 4): {4 * 50 / np.sum(batch_times):.2f} FPS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b658e320-de22-45ad-bd65-18492916e980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neural_compressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86d30044-035f-4e87-9852-aa4f5ce483b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 02:45:55 [INFO] Start auto tuning.\n",
      "2025-05-13 02:45:55 [INFO] Create evaluation function according to evaluation dataloader and metric                and Execute the tuning process.\n",
      "2025-05-13 02:45:55 [INFO] Adaptor has 5 recipes.\n",
      "2025-05-13 02:45:55 [INFO] 1 recipes specified by user.\n",
      "2025-05-13 02:45:55 [INFO] 3 recipes require future tuning.\n",
      "2025-05-13 02:45:55 [INFO] *** Initialize auto tuning\n",
      "2025-05-13 02:45:55 [INFO] {\n",
      "2025-05-13 02:45:55 [INFO]     'PostTrainingQuantConfig': {\n",
      "2025-05-13 02:45:55 [INFO]         'AccuracyCriterion': {\n",
      "2025-05-13 02:45:55 [INFO]             'criterion': 'relative',\n",
      "2025-05-13 02:45:55 [INFO]             'higher_is_better': True,\n",
      "2025-05-13 02:45:55 [INFO]             'tolerable_loss': 0.8,\n",
      "2025-05-13 02:45:55 [INFO]             'absolute': None,\n",
      "2025-05-13 02:45:55 [INFO]             'keys': <bound method AccuracyCriterion.keys of <neural_compressor.config.AccuracyCriterion object at 0x7b18f9a90040>>,\n",
      "2025-05-13 02:45:55 [INFO]             'relative': 0.8\n",
      "2025-05-13 02:45:55 [INFO]         },\n",
      "2025-05-13 02:45:55 [INFO]         'approach': 'post_training_static_quant',\n",
      "2025-05-13 02:45:55 [INFO]         'backend': 'default',\n",
      "2025-05-13 02:45:55 [INFO]         'calibration_sampling_size': [\n",
      "2025-05-13 02:45:55 [INFO]             10\n",
      "2025-05-13 02:45:55 [INFO]         ],\n",
      "2025-05-13 02:45:55 [INFO]         'device': 'cpu',\n",
      "2025-05-13 02:45:55 [INFO]         'domain': 'auto',\n",
      "2025-05-13 02:45:55 [INFO]         'example_inputs': 'Not printed here due to large size tensors...',\n",
      "2025-05-13 02:45:55 [INFO]         'excluded_precisions': [\n",
      "2025-05-13 02:45:55 [INFO]         ],\n",
      "2025-05-13 02:45:55 [INFO]         'framework': 'onnxruntime',\n",
      "2025-05-13 02:45:55 [INFO]         'inputs': [\n",
      "2025-05-13 02:45:55 [INFO]         ],\n",
      "2025-05-13 02:45:55 [INFO]         'model_name': '',\n",
      "2025-05-13 02:45:55 [INFO]         'op_name_dict': None,\n",
      "2025-05-13 02:45:55 [INFO]         'op_type_dict': None,\n",
      "2025-05-13 02:45:55 [INFO]         'outputs': [\n",
      "2025-05-13 02:45:55 [INFO]         ],\n",
      "2025-05-13 02:45:55 [INFO]         'quant_format': 'QOperator',\n",
      "2025-05-13 02:45:55 [INFO]         'quant_level': 'auto',\n",
      "2025-05-13 02:45:55 [INFO]         'recipes': {\n",
      "2025-05-13 02:45:55 [INFO]             'smooth_quant': True,\n",
      "2025-05-13 02:45:55 [INFO]             'smooth_quant_args': {\n",
      "2025-05-13 02:45:55 [INFO]             },\n",
      "2025-05-13 02:45:55 [INFO]             'layer_wise_quant': False,\n",
      "2025-05-13 02:45:55 [INFO]             'layer_wise_quant_args': {\n",
      "2025-05-13 02:45:55 [INFO]             },\n",
      "2025-05-13 02:45:55 [INFO]             'fast_bias_correction': False,\n",
      "2025-05-13 02:45:55 [INFO]             'weight_correction': False,\n",
      "2025-05-13 02:45:55 [INFO]             'gemm_to_matmul': True,\n",
      "2025-05-13 02:45:55 [INFO]             'graph_optimization_level': None,\n",
      "2025-05-13 02:45:55 [INFO]             'first_conv_or_matmul_quantization': True,\n",
      "2025-05-13 02:45:55 [INFO]             'last_conv_or_matmul_quantization': True,\n",
      "2025-05-13 02:45:55 [INFO]             'pre_post_process_quantization': True,\n",
      "2025-05-13 02:45:55 [INFO]             'add_qdq_pair_to_weight': False,\n",
      "2025-05-13 02:45:55 [INFO]             'optypes_to_exclude_output_quant': [\n",
      "2025-05-13 02:45:55 [INFO]             ],\n",
      "2025-05-13 02:45:55 [INFO]             'dedicated_qdq_pair': False,\n",
      "2025-05-13 02:45:55 [INFO]             'rtn_args': {\n",
      "2025-05-13 02:45:55 [INFO]             },\n",
      "2025-05-13 02:45:55 [INFO]             'awq_args': {\n",
      "2025-05-13 02:45:55 [INFO]             },\n",
      "2025-05-13 02:45:55 [INFO]             'gptq_args': {\n",
      "2025-05-13 02:45:55 [INFO]             },\n",
      "2025-05-13 02:45:55 [INFO]             'teq_args': {\n",
      "2025-05-13 02:45:55 [INFO]             },\n",
      "2025-05-13 02:45:55 [INFO]             'autoround_args': {\n",
      "2025-05-13 02:45:55 [INFO]             }\n",
      "2025-05-13 02:45:55 [INFO]         },\n",
      "2025-05-13 02:45:55 [INFO]         'reduce_range': None,\n",
      "2025-05-13 02:45:55 [INFO]         'TuningCriterion': {\n",
      "2025-05-13 02:45:55 [INFO]             'max_trials': 100,\n",
      "2025-05-13 02:45:55 [INFO]             'objective': [\n",
      "2025-05-13 02:45:55 [INFO]                 'performance'\n",
      "2025-05-13 02:45:55 [INFO]             ],\n",
      "2025-05-13 02:45:55 [INFO]             'strategy': 'basic',\n",
      "2025-05-13 02:45:55 [INFO]             'strategy_kwargs': None,\n",
      "2025-05-13 02:45:55 [INFO]             'timeout': 0\n",
      "2025-05-13 02:45:55 [INFO]         },\n",
      "2025-05-13 02:45:55 [INFO]         'use_bf16': True,\n",
      "2025-05-13 02:45:55 [INFO]         'ni_workload_name': 'quantization'\n",
      "2025-05-13 02:45:55 [INFO]     }\n",
      "2025-05-13 02:45:55 [INFO] }\n",
      "2025-05-13 02:45:55 [WARNING] [Strategy] Please install `mpi4py` correctly if using distributed tuning; otherwise, ignore this warning.\n",
      "2025-05-13 02:45:55 [INFO] SmoothQuant args 'folding' is not set, it's True now.\n",
      "2025-05-13 02:45:55 [WARNING] The model is automatically detected as a non-NLP model. You can use 'domain' argument in 'PostTrainingQuantConfig' to overwrite it\n",
      "2025-05-13 02:45:55 [WARNING] Graph optimization level is automatically set to ENABLE_BASIC. You can use 'recipe' argument in 'PostTrainingQuantConfig'to overwrite it\n",
      "2025-05-13 02:45:58 [INFO] Start smooth model calibration.\n",
      "2025-05-13 02:46:22 [ERROR] Unexpected exception KeyError('input') happened during tuning.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/neural_compressor/quantization.py\", line 220, in fit\n",
      "    strategy.traverse()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/neural_compressor/strategy/auto.py\", line 140, in traverse\n",
      "    super().traverse()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/neural_compressor/strategy/strategy.py\", line 482, in traverse\n",
      "    self._setup_pre_tuning_algo_scheduler()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/neural_compressor/strategy/strategy.py\", line 361, in _setup_pre_tuning_algo_scheduler\n",
      "    self.model = self._pre_tuning_algo_scheduler(\"pre_quantization\")\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/neural_compressor/algorithm/algorithm.py\", line 127, in __call__\n",
      "    self._q_model = algo(self._origin_model, self._q_model, self._adaptor, self._dataloader, self._calib_iter)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/neural_compressor/algorithm/smooth_quant.py\", line 89, in __call__\n",
      "    q_model = adaptor.smooth_quant(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/neural_compressor/adaptor/onnxrt.py\", line 230, in smooth_quant\n",
      "    self.smooth_quant_model = self.sq.transform(**self.cur_sq_args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/neural_compressor/adaptor/ox_utils/smooth_quant.py\", line 183, in transform\n",
      "    self._dump_op_info(percentile, op_types, calib_iter, quantize_config)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/neural_compressor/adaptor/ox_utils/smooth_quant.py\", line 398, in _dump_op_info\n",
      "    self.max_vals_per_channel, self.shape_info, self.tensors_to_node = augment.calib_smooth(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/neural_compressor/adaptor/ox_utils/calibration.py\", line 874, in calib_smooth\n",
      "    max_val_per_channel = self._get_max_per_channel(output_dicts[key], percentile=percentile)\n",
      "KeyError: 'input'\n",
      "2025-05-13 02:46:22 [ERROR] Specified timeout or max trials is reached! Not found any quantized model which meet accuracy goal. Exit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå ÈáèÂåñÂ§±Ë¥•Ôºöq_model ÊòØ NoneÔºåËØ∑Ê£ÄÊü•Êó•ÂøóÂíåÂèÇÊï∞ËÆæÁΩÆ„ÄÇ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import onnx\n",
    "from neural_compressor import PostTrainingQuantConfig, quantization, metric\n",
    "from neural_compressor.config import AccuracyCriterion\n",
    "from neural_compressor.data import Datasets, DataLoader\n",
    "from neural_compressor.model.onnx_model import ONNXModel\n",
    "\n",
    "# Path configuration\n",
    "fp32_onnx_path = \"work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512/segnext_plantseg_iter8000.onnx\"\n",
    "int8_onnx_path = \"work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512/segnext_plantseg_quant_static.onnx\"\n",
    "img_root = \"data/plantseg115/images/test\"\n",
    "\n",
    "# Dynamically retrieve ONNX input name\n",
    "onnx_model = onnx.load(fp32_onnx_path)\n",
    "input_name = onnx_model.graph.input[0].name  # Usually 'input', but retrieved dynamically for safety\n",
    "\n",
    "# Load the model\n",
    "model = ONNXModel(fp32_onnx_path)\n",
    "\n",
    "# Build the dataloader\n",
    "dataset = Datasets(\"onnxruntime\")[\"ImageFolder\"](root=img_root)\n",
    "dataloader = DataLoader(framework=\"onnxruntime\", dataset=dataset)\n",
    "\n",
    "# Prepare a valid example input\n",
    "img_path = sorted(glob(f\"{img_root}/*.jpg\"))[0]\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.resize(img, (512, 512))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = img.astype(np.float32)\n",
    "mean = np.array([123.675, 116.28, 103.53])\n",
    "std = np.array([58.395, 57.12, 57.375])\n",
    "img = (img - mean) / std\n",
    "img = np.transpose(img, (2, 0, 1))\n",
    "img = np.expand_dims(img, axis=0)\n",
    "example_input = {input_name: img.astype(np.float32)}\n",
    "\n",
    "# Configure quantization parameters (enable smooth quant)\n",
    "config = PostTrainingQuantConfig(\n",
    "    approach=\"static\",\n",
    "    device=\"cpu\",\n",
    "    quant_format=\"QOperator\",\n",
    "    calibration_sampling_size=10,\n",
    "    accuracy_criterion=AccuracyCriterion(criterion=\"relative\", tolerable_loss=0.8),\n",
    "    example_inputs=example_input,\n",
    "    recipes={\"smooth_quant\": True}\n",
    ")\n",
    "\n",
    "# Perform quantization\n",
    "q_model = quantization.fit(\n",
    "    model=model,\n",
    "    conf=config,\n",
    "    calib_dataloader=dataloader,\n",
    "    eval_dataloader=dataloader,\n",
    "    eval_metric=metric.Metric(name=\"topk\", k=1)\n",
    ")\n",
    "\n",
    "# Save the quantized model\n",
    "if q_model is not None:\n",
    "    q_model.save_model_to_file(int8_onnx_path)\n",
    "    print(f\"INT8 ONNX model saved to: {int8_onnx_path}\")\n",
    "else:\n",
    "    print(\"Quantization failed: q_model is None. Please check logs and parameter settings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64bca0af-3461-4438-8145-11ac1fa2cecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 02:47:04 [INFO] Start auto tuning.\n",
      "2025-05-13 02:47:04 [INFO] Quantize model without tuning!\n",
      "2025-05-13 02:47:04 [INFO] Quantize the model with default configuration without evaluating the model.                To perform the tuning process, please either provide an eval_func or provide an                    eval_dataloader an eval_metric.\n",
      "2025-05-13 02:47:04 [INFO] Adaptor has 5 recipes.\n",
      "2025-05-13 02:47:04 [INFO] 0 recipes specified by user.\n",
      "2025-05-13 02:47:04 [INFO] 3 recipes require future tuning.\n",
      "2025-05-13 02:47:04 [INFO] *** Initialize auto tuning\n",
      "2025-05-13 02:47:04 [INFO] {\n",
      "2025-05-13 02:47:04 [INFO]     'PostTrainingQuantConfig': {\n",
      "2025-05-13 02:47:04 [INFO]         'AccuracyCriterion': {\n",
      "2025-05-13 02:47:04 [INFO]             'criterion': 'relative',\n",
      "2025-05-13 02:47:04 [INFO]             'higher_is_better': True,\n",
      "2025-05-13 02:47:04 [INFO]             'tolerable_loss': 0.01,\n",
      "2025-05-13 02:47:04 [INFO]             'absolute': None,\n",
      "2025-05-13 02:47:04 [INFO]             'keys': <bound method AccuracyCriterion.keys of <neural_compressor.config.AccuracyCriterion object at 0x7b191b65c5e0>>,\n",
      "2025-05-13 02:47:04 [INFO]             'relative': 0.01\n",
      "2025-05-13 02:47:04 [INFO]         },\n",
      "2025-05-13 02:47:04 [INFO]         'approach': 'post_training_dynamic_quant',\n",
      "2025-05-13 02:47:04 [INFO]         'backend': 'default',\n",
      "2025-05-13 02:47:04 [INFO]         'calibration_sampling_size': [\n",
      "2025-05-13 02:47:04 [INFO]             100\n",
      "2025-05-13 02:47:04 [INFO]         ],\n",
      "2025-05-13 02:47:04 [INFO]         'device': 'cpu',\n",
      "2025-05-13 02:47:04 [INFO]         'domain': 'auto',\n",
      "2025-05-13 02:47:04 [INFO]         'example_inputs': 'Not printed here due to large size tensors...',\n",
      "2025-05-13 02:47:04 [INFO]         'excluded_precisions': [\n",
      "2025-05-13 02:47:04 [INFO]         ],\n",
      "2025-05-13 02:47:04 [INFO]         'framework': 'onnxruntime',\n",
      "2025-05-13 02:47:04 [INFO]         'inputs': [\n",
      "2025-05-13 02:47:04 [INFO]         ],\n",
      "2025-05-13 02:47:04 [INFO]         'model_name': '',\n",
      "2025-05-13 02:47:04 [INFO]         'op_name_dict': None,\n",
      "2025-05-13 02:47:04 [INFO]         'op_type_dict': None,\n",
      "2025-05-13 02:47:04 [INFO]         'outputs': [\n",
      "2025-05-13 02:47:04 [INFO]         ],\n",
      "2025-05-13 02:47:04 [INFO]         'quant_format': 'QOperator',\n",
      "2025-05-13 02:47:04 [INFO]         'quant_level': 'auto',\n",
      "2025-05-13 02:47:04 [INFO]         'recipes': {\n",
      "2025-05-13 02:47:04 [INFO]             'smooth_quant': False,\n",
      "2025-05-13 02:47:04 [INFO]             'smooth_quant_args': {\n",
      "2025-05-13 02:47:04 [INFO]             },\n",
      "2025-05-13 02:47:04 [INFO]             'layer_wise_quant': False,\n",
      "2025-05-13 02:47:04 [INFO]             'layer_wise_quant_args': {\n",
      "2025-05-13 02:47:04 [INFO]             },\n",
      "2025-05-13 02:47:04 [INFO]             'fast_bias_correction': False,\n",
      "2025-05-13 02:47:04 [INFO]             'weight_correction': False,\n",
      "2025-05-13 02:47:04 [INFO]             'gemm_to_matmul': True,\n",
      "2025-05-13 02:47:04 [INFO]             'graph_optimization_level': None,\n",
      "2025-05-13 02:47:04 [INFO]             'first_conv_or_matmul_quantization': True,\n",
      "2025-05-13 02:47:04 [INFO]             'last_conv_or_matmul_quantization': True,\n",
      "2025-05-13 02:47:04 [INFO]             'pre_post_process_quantization': True,\n",
      "2025-05-13 02:47:04 [INFO]             'add_qdq_pair_to_weight': False,\n",
      "2025-05-13 02:47:04 [INFO]             'optypes_to_exclude_output_quant': [\n",
      "2025-05-13 02:47:04 [INFO]             ],\n",
      "2025-05-13 02:47:04 [INFO]             'dedicated_qdq_pair': False,\n",
      "2025-05-13 02:47:04 [INFO]             'rtn_args': {\n",
      "2025-05-13 02:47:04 [INFO]             },\n",
      "2025-05-13 02:47:04 [INFO]             'awq_args': {\n",
      "2025-05-13 02:47:04 [INFO]             },\n",
      "2025-05-13 02:47:04 [INFO]             'gptq_args': {\n",
      "2025-05-13 02:47:04 [INFO]             },\n",
      "2025-05-13 02:47:04 [INFO]             'teq_args': {\n",
      "2025-05-13 02:47:04 [INFO]             },\n",
      "2025-05-13 02:47:04 [INFO]             'autoround_args': {\n",
      "2025-05-13 02:47:04 [INFO]             }\n",
      "2025-05-13 02:47:04 [INFO]         },\n",
      "2025-05-13 02:47:04 [INFO]         'reduce_range': None,\n",
      "2025-05-13 02:47:04 [INFO]         'TuningCriterion': {\n",
      "2025-05-13 02:47:04 [INFO]             'max_trials': 100,\n",
      "2025-05-13 02:47:04 [INFO]             'objective': [\n",
      "2025-05-13 02:47:04 [INFO]                 'performance'\n",
      "2025-05-13 02:47:04 [INFO]             ],\n",
      "2025-05-13 02:47:04 [INFO]             'strategy': 'basic',\n",
      "2025-05-13 02:47:04 [INFO]             'strategy_kwargs': None,\n",
      "2025-05-13 02:47:04 [INFO]             'timeout': 0\n",
      "2025-05-13 02:47:04 [INFO]         },\n",
      "2025-05-13 02:47:04 [INFO]         'use_bf16': True,\n",
      "2025-05-13 02:47:04 [INFO]         'ni_workload_name': 'quantization'\n",
      "2025-05-13 02:47:04 [INFO]     }\n",
      "2025-05-13 02:47:04 [INFO] }\n",
      "2025-05-13 02:47:04 [WARNING] [Strategy] Please install `mpi4py` correctly if using distributed tuning; otherwise, ignore this warning.\n",
      "2025-05-13 02:47:04 [WARNING] The model is automatically detected as a non-NLP model. You can use 'domain' argument in 'PostTrainingQuantConfig' to overwrite it\n",
      "2025-05-13 02:47:04 [WARNING] Graph optimization level is automatically set to ENABLE_BASIC. You can use 'recipe' argument in 'PostTrainingQuantConfig'to overwrite it\n",
      "2025-05-13 02:47:07 [INFO] Do not evaluate the baseline and quantize the model with default configuration.\n",
      "2025-05-13 02:47:20 [INFO] Quantize the model with default config.\n",
      "2025-05-13 02:47:57 [INFO] |**********Mixed Precision Statistics*********|\n",
      "2025-05-13 02:47:57 [INFO] +-----------------------+-------+------+------+\n",
      "2025-05-13 02:47:57 [INFO] |        Op Type        | Total | INT8 | FP32 |\n",
      "2025-05-13 02:47:57 [INFO] +-----------------------+-------+------+------+\n",
      "2025-05-13 02:47:57 [INFO] |          Conv         |  504  | 504  |  0   |\n",
      "2025-05-13 02:47:57 [INFO] |         MatMul        |   46  |  0   |  46  |\n",
      "2025-05-13 02:47:57 [INFO] |         Gather        |  167  |  0   | 167  |\n",
      "2025-05-13 02:47:57 [INFO] | DynamicQuantizeLinear |  428  | 428  |  0   |\n",
      "2025-05-13 02:47:57 [INFO] +-----------------------+-------+------+------+\n",
      "2025-05-13 02:47:57 [INFO] Pass quantize model elapsed time: 36673.41 ms\n",
      "2025-05-13 02:47:57 [INFO] Save tuning history to /workspace/PlantSeg/nc_workspace/2025-05-13_02-23-48/./history.snapshot.\n",
      "2025-05-13 02:47:57 [INFO] [Strategy] Found the model meets accuracy requirements, ending the tuning process.\n",
      "2025-05-13 02:47:57 [INFO] Specified timeout or max trials is reached! Found a quantized model which meet accuracy goal. Exit.\n",
      "2025-05-13 02:47:57 [INFO] Save deploy yaml to /workspace/PlantSeg/nc_workspace/2025-05-13_02-23-48/deploy.yaml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dynamic quantized model saved to: work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512/segnext_plantseg_quant_dynamic.onnx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from neural_compressor import PostTrainingQuantConfig, quantization\n",
    "from neural_compressor.model.onnx_model import ONNXModel\n",
    "\n",
    "# File paths\n",
    "fp32_onnx_path = \"work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512/segnext_plantseg_iter8000.onnx\"\n",
    "int8_onnx_path = \"work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512/segnext_plantseg_quant_dynamic.onnx\"\n",
    "\n",
    "# Load the original ONNX model\n",
    "model = ONNXModel(fp32_onnx_path)\n",
    "\n",
    "# Configure dynamic quantization\n",
    "config = PostTrainingQuantConfig(\n",
    "    approach=\"dynamic\",           # Use dynamic quantization\n",
    "    device=\"cpu\",                 # Typically run on CPU\n",
    "    quant_format=\"QOperator\"      # Use standard quantization format\n",
    ")\n",
    "\n",
    "# Perform quantization\n",
    "q_model = quantization.fit(\n",
    "    model=model,\n",
    "    conf=config\n",
    ")\n",
    "\n",
    "# Save the quantized INT8 model\n",
    "if q_model is not None:\n",
    "    q_model.save_model_to_file(int8_onnx_path)\n",
    "    print(f\"Dynamic quantized model saved to: {int8_onnx_path}\")\n",
    "else:\n",
    "    print(\"Quantization failed: q_model is None. Please check the path or model structure.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49bd7d0d-2dfc-430e-b4bc-2fe8d8083e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [01:38<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä === ONNX Quantized Model Evaluation Report ===\n",
      "üíæ Model Size on Disk: 49.67 MB\n",
      "üéØ Pixel Accuracy: 81.88%\n",
      "üìè mIoU: 0.88%\n",
      "‚è±Ô∏è  Inference Latency (median): 1872.40 ms\n",
      "‚è±Ô∏è  Inference Latency (95%): 1898.49 ms\n",
      "üöÄ  Throughput (single): 0.53 FPS\n",
      "üöÄ  Batch Throughput (BS=4): 0.55 FPS\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import cv2\n",
    "from glob import glob\n",
    "\n",
    "# Path to the quantized ONNX model\n",
    "onnx_path = 'work_dirs/segnext_mscan-l_1xb16-adamw-40k_plantseg115-512x512/segnext_plantseg_quant_dynamic.onnx'\n",
    "onnx_model_size = os.path.getsize(onnx_path) / (1024 * 1024)\n",
    "\n",
    "# Create ONNX Runtime session\n",
    "session = ort.InferenceSession(onnx_path, providers=['CPUExecutionProvider'])\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "# Image preprocessing (same as training)\n",
    "def preprocess(img):\n",
    "    img = cv2.resize(img, (512, 512))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32)\n",
    "    mean = np.array([123.675, 116.28, 103.53])\n",
    "    std = np.array([58.395, 57.12, 57.375])\n",
    "    img = (img - mean) / std\n",
    "    img = np.transpose(img, (2, 0, 1))  # HWC -> CHW\n",
    "    img = np.expand_dims(img, axis=0)  # CHW -> NCHW\n",
    "    return img.astype(np.float32)\n",
    "\n",
    "# Dataset paths\n",
    "img_dir = 'data/plantseg115/images/test'\n",
    "gt_dir  = 'data/plantseg115/annotations/test'\n",
    "img_paths = sorted(glob(f\"{img_dir}/*.jpg\"))\n",
    "gt_paths  = sorted(glob(f\"{gt_dir}/*.png\"))\n",
    "img_paths = img_paths[:50]\n",
    "gt_paths = gt_paths[:50]\n",
    "assert len(img_paths) == len(gt_paths) and len(img_paths) > 0, \"No test images found!\"\n",
    "\n",
    "# Evaluate accuracy and mIoU\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "for img_path, gt_path in tqdm(zip(img_paths, gt_paths), total=len(img_paths)):\n",
    "    img = preprocess(cv2.imread(img_path))\n",
    "    gt  = cv2.imread(gt_path, cv2.IMREAD_GRAYSCALE)\n",
    "    gt  = cv2.resize(gt, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    pred_logits = session.run([output_name], {input_name: img})[0]  # (1, C, H, W)\n",
    "    pred_mask = np.argmax(pred_logits[0], axis=0)                   # (H, W)\n",
    "    pred_mask = cv2.resize(pred_mask.astype(np.uint8), (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    valid = gt != 255\n",
    "    all_preds.extend(pred_mask[valid].flatten())\n",
    "    all_labels.extend(gt[valid].flatten())\n",
    "\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "conf = confusion_matrix(all_labels, all_preds, labels=range(116))\n",
    "intersection = np.diag(conf)\n",
    "union = conf.sum(1) + conf.sum(0) - intersection\n",
    "miou = (intersection / np.maximum(union, 1)).mean()\n",
    "\n",
    "# Measure inference latency (single image)\n",
    "latencies = []\n",
    "dummy_img = preprocess(cv2.imread(img_paths[0]))\n",
    "\n",
    "for _ in range(100):\n",
    "    start = time.time()\n",
    "    _ = session.run(None, {input_name: dummy_img})\n",
    "    latencies.append(time.time() - start)\n",
    "\n",
    "# Measure throughput (batch size = 4)\n",
    "batch_input = np.repeat(dummy_img, repeats=4, axis=0)\n",
    "batch_times = []\n",
    "for _ in range(50):\n",
    "    start = time.time()\n",
    "    _ = session.run(None, {input_name: batch_input})\n",
    "    batch_times.append(time.time() - start)\n",
    "\n",
    "# Print evaluation report\n",
    "print(\"\\n=== ONNX Quantized Model Evaluation Report ===\")\n",
    "print(f\"Model Size on Disk: {onnx_model_size:.2f} MB\")\n",
    "print(f\"Pixel Accuracy: {acc * 100:.2f}%\")\n",
    "print(f\"mIoU: {miou * 100:.2f}%\")\n",
    "print(f\"Inference Latency (median): {np.median(latencies)*1000:.2f} ms\")\n",
    "print(f\"Inference Latency (95th percentile): {np.percentile(latencies, 95)*1000:.2f} ms\")\n",
    "print(f\"Throughput (single): {1 / np.mean(latencies):.2f} FPS\")\n",
    "print(f\"Batch Throughput (batch size = 4): {4 * 50 / np.sum(batch_times):.2f} FPS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc68a204-2405-44ef-828f-a51fa6007f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "print(session.get_providers())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b4a7ac-9101-4027-bb8f-e27d240c34c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
